{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f79cded",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb9d07",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Extract text from file names as well as labels\n",
    "def read_text_files_with_labels(path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    class_folders = sorted(os.listdir(path))  # Assuming class folders are sorted\n",
    "    label_map = {class_name: idx for idx, class_name in enumerate(class_folders)}\n",
    "\n",
    "    for class_name in class_folders:\n",
    "        class_path = os.path.join(path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            file_names = os.listdir(class_path)\n",
    "            for file_name in file_names:\n",
    "                file_path = os.path.join(class_path, file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    file_name_no_ext, _ = os.path.splitext(file_name)\n",
    "                    text = file_name_no_ext.replace('_', ' ')\n",
    "                    text_without_digits = re.sub(r'\\d+', '', text)\n",
    "                    texts.append(text_without_digits)\n",
    "                    labels.append(label_map[class_name])\n",
    "\n",
    "    return np.array(texts), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be834e3a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define your dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da28eb1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class DistilBERTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DistilBERTClassifier, self).__init__()\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(self.distilbert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        pooled_output = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        output = self.drop(pooled_output[:,0])\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36f1dd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define training function\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in iterator:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_ids, attention_mask)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d3890",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define evaluation function\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            output = model(input_ids, attention_mask)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d141560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)  # Assuming input_ids are in the batch\n",
    "            attention_mask = batch['attention_mask'].to(device)  # Assuming attention_mask is in the batch\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "\n",
    "            # Get predictions\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            # Convert predictions to CPU and append to the list\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90099342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_PATH = r\"C:\\Users\\rober\\OneDrive - University of Calgary\\Projects\\Garbage-classification\\CVPR_2024_dataset\\CVPR_2024_dataset\\Train\"\n",
    "TRAIN_PATH = r\"/work/TALC/enel645_2025w/garbage_data/CVPR_2024_dataset_Train\"\n",
    "# VAL_PATH = r\"C:\\Users\\rober\\OneDrive - University of Calgary\\Projects\\Garbage-classification\\CVPR_2024_dataset\\CVPR_2024_dataset\\Validation\"\n",
    "VAL_PATH = r\"/work/TALC/enel645_2025w/garbage_data/CVPR_2024_dataset_Val\"\n",
    "# TEST_PATH = r\"C:\\Users\\rober\\OneDrive - University of Calgary\\Projects\\Garbage-classification\\CVPR_2024_dataset\\CVPR_2024_dataset\\Test\"\n",
    "TEST_PATH = r\"/work/TALC/enel645_2025w/garbage_data/CVPR_2024_dataset_Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ccf20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train,labels_train = read_text_files_with_labels(TRAIN_PATH)\n",
    "text_val,labels_val = read_text_files_with_labels(VAL_PATH)\n",
    "text_test,labels_test = read_text_files_with_labels(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a4ffa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(text_train.shape)\n",
    "print(labels_train.shape)\n",
    "print(text_val.shape)\n",
    "print(labels_val.shape)\n",
    "print(text_test.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f8dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca15c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize data\n",
    "max_len = 24\n",
    "dataset_train = CustomDataset(text_train, labels_train, tokenizer, max_len)\n",
    "dataset_val = CustomDataset(text_val, labels_val, tokenizer, max_len)\n",
    "dataset_test = CustomDataset(text_test, labels_test, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64847ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_loader = DataLoader(dataset_train, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(dataset_test, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ca7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 1e+10 # best loss tracker\n",
    "EPOCHS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DistilBERTClassifier(num_classes=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b8343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}')\n",
    "    val_loss = evaluate(model, val_loader, criterion, device)\n",
    "    print(f'Epoch: {epoch+1}, Val Loss: {val_loss:.4f}')\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d304a4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a57708",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "# Evaluation\n",
    "test_predictions = predict(model, test_loader, device)\n",
    "print(f\"Accuracy:  {(test_predictions == labels_test).sum()/labels_test.size:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e56683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445b26e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aef484",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels_test, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28249b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792bff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
