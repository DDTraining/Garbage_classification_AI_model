{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef16722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import matplotlib.pylab as plt\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fd3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb57d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a0626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c9cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = r\"/work/TALC/enel645_2025w/garbage_data/CVPR_2024_dataset_Train\"\n",
    "VAL_PATH = r\"/work/TALC/enel645_2025w/garbage_data/CVPR_2024_dataset_Val\"\n",
    "TEST_PATH = r\"/work/TALC/enel645_2025w/garbage_data/CVPR_2024_dataset_Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21350bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deebfd0e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Transforms \n",
    "torchvision_transform = transforms.Compose([transforms.Resize((224,224)),\\\n",
    "    transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406] ,std=[0.229, 0.224, 0.225] )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f1ddc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "torchvision_transform_test = transforms.Compose([transforms.Resize((224,224)),\\\n",
    "    transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406] ,std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4097b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = ImageFolder(root=TRAIN_PATH, transform= torchvision_transform)\n",
    "val_dataset = ImageFolder(root=VAL_PATH, transform= torchvision_transform)\n",
    "test_dataset = ImageFolder(root=TEST_PATH, transform= torchvision_transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59638aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size and number of workers (adjust as needed)\n",
    "batch_size = 32\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274101f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "class_names = train_dataset.classes\n",
    "print(class_names)\n",
    "print(\"Train set:\", len(trainloader)*batch_size)\n",
    "print(\"Val set:\", len(valloader)*batch_size)\n",
    "print(\"Test set:\", len(testloader)*batch_size)\n",
    "train_iterator = iter(trainloader)\n",
    "train_batch = next(train_iterator)\n",
    "print(train_batch[0].size())\n",
    "print(train_batch[1].size())\n",
    "plt.figure()\n",
    "plt.imshow(train_batch[0].numpy()[16].transpose(1,2,0))\n",
    "plt.show()\n",
    "class GarbageModel(nn.Module):\n",
    "    def __init__(self,  num_classes, input_shape, transfer=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transfer = transfer\n",
    "        self.num_classes = num_classes\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # transfer learning if weights=True\n",
    "        self.feature_extractor = models.resnet18(weights=transfer)\n",
    "\n",
    "        if self.transfer:\n",
    "            # layers are frozen by using eval()\n",
    "            self.feature_extractor.eval()\n",
    "            # freeze params\n",
    "            for param in self.feature_extractor.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        n_features = self._get_conv_output(self.input_shape)\n",
    "        self.classifier = nn.Linear(n_features, num_classes)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "        output_feat = self.feature_extractor(tmp_input) \n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "\n",
    "    # will be used during inference\n",
    "    def forward(self, x):\n",
    "       x = self.feature_extractor(x)\n",
    "       x = x.view(x.size(0), -1)\n",
    "       x = self.classifier(x)\n",
    "       \n",
    "       return x\n",
    "net = GarbageModel(4, (3,224,224), True)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss() # Loss function\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr = 0.001)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "nepochs = 10\n",
    "PATH = './garbage_net.pth' # Path to save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 1e+20\n",
    "for epoch in range(nepochs):  # loop over the dataset multiple times\n",
    "    # Training Loop\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    print(f'{epoch + 1},  train loss: {train_loss / i:.3f},', end = ' ')\n",
    "    scheduler.step()\n",
    "    \n",
    "    val_loss = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "        print(f'val loss: {val_loss / i:.3f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_loss:\n",
    "            print(\"Saving model\")\n",
    "            torch.save(net.state_dict(), PATH)\n",
    "            best_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished Training')\n",
    "# Load the best model to be used in the test set\n",
    "net = GarbageModel(4, (3,224,224), False)\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "#net.load_state_dict(torch.load(PATH))\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4268afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy of the network on the test images: {100 * correct / total} %')\n",
    "print(total)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
