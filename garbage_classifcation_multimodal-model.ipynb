{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a750acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    """"
Hybrid Garbage Classification Model 

This script implements a hybrid model for garbage classification that combines:
- Image features using ResNet18
- Text features using DistilBERT

The model fuses features from both modalities to improve classification performance
beyond what either modality could achieve individually. The implementation includes
both an initial training phase and an automatic fine-tuning phase.
""" \n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bca60d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d151ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ddbaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "NUM_CLASSES = 4\n",
    "MAX_TEXT_LENGTH = 24\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "IMAGE_SIZE = 224\n",
    "LEARNING_RATE = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5960e6f8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Paths (Replace with actual dataset paths)\n",
    "TRAIN_PATH = \"/work/TALC/enel645_2025w/garbage_data/CVPR_2024_dataset_Train\"\n",
    "VAL_PATH = \"/work/TALC/enel645_2025w/garbage_data/CVPR_2024_dataset_Val\"\n",
    "TEST_PATH = \"/work/TALC/enel645_2025w/garbage_data/CVPR_2024_dataset_Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41579acc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "def extract_text_from_path(file_path):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_name_no_ext, _ = os.path.splitext(file_name)\n",
    "    text = file_name_no_ext.replace('_', ' ')\n",
    "    return re.sub(r'\\d+', '', text)  # Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8994db",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load dataset paths\n",
    "def get_files_with_labels(root_path):\n",
    "    image_paths, texts, labels = [], [], []\n",
    "    class_folders = sorted(os.listdir(root_path))\n",
    "    label_map = {class_name: idx for idx, class_name in enumerate(class_folders)}\n",
    "\n",
    "    for class_name in class_folders:\n",
    "        class_path = os.path.join(root_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for file_name in os.listdir(class_path):\n",
    "                file_path = os.path.join(class_path, file_name)\n",
    "                if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image_paths.append(file_path)\n",
    "                    texts.append(extract_text_from_path(file_path))\n",
    "                    labels.append(label_map[class_name])\n",
    "    return image_paths, texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd312ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8053d11",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db7c93c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class HybridDataset(Dataset):\n",
    "    def __init__(self, image_paths, texts, labels, tokenizer, transform, max_len=MAX_TEXT_LENGTH):\n",
    "        self.image_paths = image_paths\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "\n",
    "        # Process text\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx], padding='max_length', truncation=True,\n",
    "            max_length=self.max_len, return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'image': image,\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c398a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Fusion Module\n",
    "class AttentionFusion(nn.Module):\n",
    "    def __init__(self, img_dim=1024, text_dim=1024):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(img_dim + text_dim, 1)\n",
    "\n",
    "    def forward(self, img_features, text_features):\n",
    "        weights = torch.sigmoid(self.attn(torch.cat([img_features, text_features], dim=1)))\n",
    "        return weights * img_features + (1 - weights) * text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808f6ed",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Hybrid Model\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        self.image_model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
    "        self.image_model = nn.Sequential(*list(self.image_model.children())[:-1])\n",
    "        self.image_fc = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.text_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.text_fc = nn.Sequential(\n",
    "            nn.Linear(768, 1024),\n",
    "            nn.BatchNorm1d(1024), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fusion = AttentionFusion(img_dim=1024, text_dim=1024)\n",
    "        self.classifier = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        img_features = self.image_model(images).squeeze()\n",
    "        # Ensure img_features has the right shape\n",
    "        if len(img_features.shape) == 1:\n",
    "            img_features = img_features.unsqueeze(0)\n",
    "        img_features = self.image_fc(img_features)\n",
    "        \n",
    "        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        text_features = self.text_fc(text_output[:, 0, :])\n",
    "        fused_features = self.fusion(img_features, text_features)\n",
    "        return self.classifier(fused_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e7cc5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Training and Evaluation Functions\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=EPOCHS):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, correct_train, total_train = 0, 0, 0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images, input_ids, attn_mask, labels = batch['image'].to(device), batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, input_ids, attn_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "            correct_train += (predictions == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_acc = correct_train / total_train\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, correct_val, total_val = 0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validating\"):\n",
    "                images, input_ids, attn_mask, labels = batch['image'].to(device), batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n",
    "                outputs = model(images, input_ids, attn_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predictions = outputs.argmax(dim=1)\n",
    "                correct_val += (predictions == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_acc = correct_val / total_val\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_hybrid_model.pth')\n",
    "            print(\"Saved Best Model!\")\n",
    "\n",
    "    model.load_state_dict(torch.load('best_hybrid_model.pth'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b20085",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images, input_ids, attn_mask, labels = batch['image'].to(device), batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)\n",
    "            outputs = model(images, input_ids, attn_mask)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = (np.array(all_preds) == np.array(all_labels)).mean()\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f70789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load tokenizer\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    # Load datasets\n",
    "    train_image_paths, train_texts, train_labels = get_files_with_labels(TRAIN_PATH)\n",
    "    val_image_paths, val_texts, val_labels = get_files_with_labels(VAL_PATH)\n",
    "    test_image_paths, test_texts, test_labels = get_files_with_labels(TEST_PATH)\n",
    "\n",
    "    train_dataset = HybridDataset(train_image_paths, train_texts, train_labels, tokenizer, train_transform)\n",
    "    val_dataset = HybridDataset(val_image_paths, val_texts, val_labels, tokenizer, test_transform)\n",
    "    test_dataset = HybridDataset(test_image_paths, test_texts, test_labels, tokenizer, test_transform)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Initialize model\n",
    "    model = HybridModel().to(device)\n",
    "\n",
    "    # Define optimizer and scheduler\n",
    "    optimizer = optim.AdamW([\n",
    "        {\"params\": model.image_model.parameters(), \"lr\": 1e-4},\n",
    "        {\"params\": model.text_model.parameters(), \"lr\": 5e-6},\n",
    "        {\"params\": model.classifier.parameters(), \"lr\": 1e-4},\n",
    "    ])\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
    "\n",
    "    # Define loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Starting training...\")\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=EPOCHS)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"Evaluating on test set...\")\n",
    "    evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
